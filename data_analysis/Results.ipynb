{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copyright 2016 Google Inc.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "#\n",
    "################################################################################\n",
    "#\n",
    "# Notebook to process the ratings and produce plots and tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import bs4\n",
    "import collections\n",
    "import csv\n",
    "import itertools\n",
    "import jsonpickle\n",
    "import math\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "import sklearn.cross_validation\n",
    "\n",
    "sys.path.append(\n",
    "    os.path.abspath(os.path.join(os.path.dirname('__file__'), os.path.pardir)))\n",
    "\n",
    "import logs_processing.click_model as click_model\n",
    "from logs_processing.create_tasks import Action, LogItem\n",
    "from logs_processing.fields import orig_query, rel_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "current_palette = sns.color_palette()\n",
    "sns.palplot(current_palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CF = '<DIRECTORY_WITH_EXPORTED_CROWD_FLOWER_RESULT_CSVs>'\n",
    "SPAMMER_FILENAMES = ['spammer1.txt', 'spammer2.txt']\n",
    "RESULTS_D = 'f789260_D.full.csv'\n",
    "RESULTS_AR = ['f842336_A+R.part1.csv', 'f845369_A+R.part2.csv', 'f845808_A+R.part3.csv', 'f846814_A+R.part4.csv']\n",
    "TASK_FILE = 'task.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "USE_CF_TRUST = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the  data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read spammers data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spammers = set()\n",
    "for s_file_name in SPAMMER_FILENAMES:\n",
    "    with open(os.path.join(CF, s_file_name)) as f:\n",
    "        for worker_id in f:\n",
    "            spammers.add(worker_id.rstrip())\n",
    "\n",
    "print '%d spammers' % len(spammers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "log_id_to_rel = collections.defaultdict(click_model.RelContainer)\n",
    "log_id_to_query = {}\n",
    "good_worker_ratings = 0\n",
    "total_ratings = 0\n",
    "all_workers = set()\n",
    "with open(os.path.join(CF, RESULTS_D)) as results_D:\n",
    "    for row in csv.DictReader(results_D):\n",
    "        worker_id = row['_worker_id']\n",
    "        all_workers.add(worker_id)\n",
    "        total_ratings += 1\n",
    "        if worker_id not in spammers:\n",
    "            good_worker_ratings += 1\n",
    "            trust = float(row['_trust']) if USE_CF_TRUST else 1\n",
    "            log_id = row['log_id']\n",
    "            click_model.RelContainer.add_rel(log_id_to_rel[log_id].Ds, row[rel_column['D']], trust)\n",
    "            log_id_to_query[log_id] = row[orig_query['D']]\n",
    "print '(D) %.1f%% ratings form spammers' % (100 - 100 * good_worker_ratings / total_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "good_worker_ratings = 0\n",
    "total_ratings = 0\n",
    "yes_detailed = []\n",
    "for result_AR in RESULTS_AR:\n",
    "    with open(os.path.join(CF, result_AR)) as results_AR:\n",
    "        for row in csv.DictReader(results_AR):\n",
    "            worker_id = row['_worker_id']\n",
    "            all_workers.add(worker_id)\n",
    "            total_ratings += 1\n",
    "            if worker_id not in spammers:\n",
    "                good_worker_ratings +=1\n",
    "                trust = float(row['_trust']) if USE_CF_TRUST else 1\n",
    "                log_id = row['log_id']\n",
    "                click_model.RelContainer.add_rel(log_id_to_rel[log_id].Rs, row[rel_column['R']], trust)\n",
    "                query = row[orig_query['R']]\n",
    "                if row['yes_detailed']:\n",
    "                    yes_detailed.append(row['yes_detailed'])\n",
    "                old_query = log_id_to_query.setdefault(log_id, query)\n",
    "                if old_query != query:\n",
    "                    print >>sys.stderr, ('The same log_id '\n",
    "                            '(%s) maps to two different queries: [%s] and [%s]' % (\n",
    "                                    log_id, old_query, query))\n",
    "                    sys.exit(1)\n",
    "\n",
    "print '%d items with complete relevance' % sum(\n",
    "        1 for r in log_id_to_rel.itervalues() if r)\n",
    "\n",
    "print '%d queries with at least one completely judged document' % len(set(\n",
    "        log_id_to_query[k] for k, r in log_id_to_rel.iteritems() if r))\n",
    "\n",
    "print '%d workers in total' % len(all_workers)\n",
    "\n",
    "print '(R) %.1f%% ratings form spammers' % (100 - 100 * good_worker_ratings / total_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def percentages(counter):\n",
    "    s = sum(counter.values())\n",
    "    return ['%s: %.1f%%' % (k, v / s * 100) for k, v in counter.most_common()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print percentages(collections.Counter(yes_detailed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Ds = collections.Counter(x[0] for rel in log_id_to_rel.itervalues() for x in rel.Ds)\n",
    "Rs = collections.Counter(x[0] for rel in log_id_to_rel.itervalues() for x in rel.Rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print percentages(Ds)\n",
    "print percentages(Rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation between R and D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "most_common_rel_labels = []\n",
    "for rel in log_id_to_rel.itervalues():\n",
    "    most_common_rel_labels.append({'D': click_model.rel_most_common(rel.Ds), 'R': click_model.rel_most_common(rel.Rs)})\n",
    "mc_rels = pd.DataFrame(most_common_rel_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scipy.stats.pearsonr(mc_rels['R'], mc_rels['D'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scipy.stats.spearmanr(mc_rels['R'], mc_rels['D'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = sns.regplot(x='R', y='D', data=mc_rels, x_jitter=.1, y_jitter=.1)\n",
    "ax.figure.savefig('R_D_correlation.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read SERPs and logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "with open(os.path.join(CF, TASK_FILE)) as task_file:\n",
    "    sat_labels = []\n",
    "    num_skipped = 0\n",
    "    num_sat_true = 0\n",
    "    num_total = 0\n",
    "    reader = csv.DictReader(task_file)\n",
    "    for key, query_rows_iter in itertools.groupby(reader,\n",
    "                    key=lambda row: (row['log_id'].split('_')[:-1], # SERP id\n",
    "                                     row[orig_query['query']],\n",
    "                                     row['sat_feedback'])):\n",
    "        sat = key[2]\n",
    "        if sat == 'undefined':\n",
    "            print >>sys.stderr, 'Undefined sat label for query [%s]' % query\n",
    "        sat_labels.append(sat)\n",
    "        sat = click_model.parse_sat(sat)\n",
    "        if sat is None:\n",
    "            num_skipped += 1\n",
    "            continue\n",
    "        elif sat:\n",
    "            num_sat_true += 1\n",
    "        data_row = {'query': key[1], 'sat': sat, 'session': [], 'serp': []}\n",
    "        for row in query_rows_iter:\n",
    "            data_row['session'].append(jsonpickle.decode(row['actions']))\n",
    "            data_row['serp'].append(\n",
    "                    bs4.BeautifulSoup(row['snippet'], 'html.parser').li)\n",
    "        data.append(data_row)\n",
    "        num_total += 1\n",
    "    print collections.Counter(sat_labels)\n",
    "    print 'Skipped %d rows out of %d' % (num_skipped, num_total + num_skipped)\n",
    "    print '%.1f%% of SAT labels in the data' % (num_sat_true / num_total * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print '%d queries left' % len(data)\n",
    "print '%d SERP items w/ ratings' % sum(sum(1 for l in row['session'] if log_id_to_rel[l.log_id]) for row in data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the heavy lifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MODELS = {\n",
    "    'CAS': click_model.CAS(log_id_to_rel),\n",
    "    'CASnod': click_model.CAS(log_id_to_rel, use_D=False),\n",
    "    'CASnosat': click_model.CAS(log_id_to_rel, sat_term_weight=0),\n",
    "    'CASnoreg': click_model.CAS(log_id_to_rel, reg_coeff=0),\n",
    "    'random': click_model.RandomSatModel(),\n",
    "    'PBM': click_model.PyClickModel('PBM', log_id_to_rel),\n",
    "    'UBM': click_model.PyClickModel('UBM', log_id_to_rel),\n",
    "    'DCG': click_model.DCG(log_id_to_rel),\n",
    "    'uUBM': click_model.uUBM(log_id_to_rel),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_performance(index, train_data, test_data, result_queue):\n",
    "    result = {}\n",
    "    for name, model in MODELS.iteritems():\n",
    "        try:\n",
    "            params = model.train(train_data)\n",
    "            ll_values_test = [\n",
    "                    model.log_likelihood(params,\n",
    "                                         d['session'], d['serp'], d['sat'],\n",
    "                                         f_only=True\n",
    "                    ) for d in test_data\n",
    "            ]\n",
    "            result[name] = {}\n",
    "            result[name]['full'] = np.average([l.full for l in ll_values_test])\n",
    "            result[name]['click'] = np.average([l.clicks for l in ll_values_test])\n",
    "            result[name]['sat'] = np.average([l.sat for l in ll_values_test])\n",
    "            result[name]['utility'] = [model.utility(params, d['session'], d['serp']) for d in test_data]\n",
    "            result[name]['sat pearson'] = scipy.stats.pearsonr(\n",
    "                    [int(d['sat']) for d in test_data],\n",
    "                    result[name]['utility']\n",
    "            )[0]\n",
    "        except Exception, e:\n",
    "            result[name] = sys.exc_info()\n",
    "    result_queue.put((index, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_REPETITIONS = 1\n",
    "N_FOLDS = 3\n",
    "N = len(data)\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_queue = multiprocessing.Queue()\n",
    "workers = []\n",
    "for rep_index in xrange(N_REPETITIONS):\n",
    "    for fold_num, (train_index, test_index) in enumerate(sklearn.cross_validation.KFold(N, n_folds=N_FOLDS,\n",
    "                                                                                        shuffle=True,\n",
    "                                                                                        random_state=rep_index)):\n",
    "        w = multiprocessing.Process(target=compute_performance,\n",
    "                    args=((rep_index, fold_num), data[train_index], data[test_index], result_queue))\n",
    "        workers.append(w)\n",
    "        w.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for i in xrange(len(workers)):\n",
    "    try:\n",
    "        results.append(result_queue.get(timeout=300))\n",
    "        print >>sys.stderr, i,\n",
    "    except multiprocessing.TimeoutError:\n",
    "        print >>sys.stderr, '..',\n",
    "print len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for w in workers:\n",
    "    w.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def flatten(results):\n",
    "    out = []\n",
    "    for idx, result in results:\n",
    "        for model, r in result.iteritems():\n",
    "            if isinstance(r, tuple):\n",
    "                print >>sys.stderr, r\n",
    "            else:\n",
    "                out += [{'rep': idx[0], 'fold': idx[1], 'model': model, 'metric': k, 'value': v} for (k, v) in r.iteritems()]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = pd.DataFrame(flatten(results))\n",
    "d.to_pickle('results.df')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric-metric correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def utility(rep, fold, model):\n",
    "    return d[d['rep'] == rep][d['fold'] == fold][d['model'] == model][d['metric'] == 'utility'].iloc[0]['value']\n",
    "#utility(0, 0, 'CAS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correlations = {}\n",
    "model_names = ['CASnod', 'CASnosat', 'CASnoreg',\n",
    "          'CAS',\n",
    "          'UBM', 'PBM',\n",
    "          'DCG', 'uUBM']\n",
    "for i in xrange(len(model_names)):\n",
    "    m1 = model_names[i]\n",
    "    correlations[m1] = {}\n",
    "    for m2 in model_names[:i]:\n",
    "        vals = []\n",
    "        for rep in xrange(N_REPETITIONS):\n",
    "            for fold in xrange(N_FOLDS):\n",
    "                try:\n",
    "                    m1_utility = utility(rep, fold, m1)\n",
    "                    m2_utility = utility(rep, fold, m2)\n",
    "                    vals.append(scipy.stats.pearsonr(m1_utility, m2_utility)[0])\n",
    "                except IndexError as e:\n",
    "                    print >>sys.stderr, 'Missing value: rep=%d, fold=%d, m1=%s, m2=%s' % (rep, fold, m1, m2)\n",
    "                    continue                   \n",
    "        correlations[m1][m2] = np.mean(vals)\n",
    "correlations = pd.DataFrame(correlations, index=model_names[:-1], columns=model_names[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print correlations.to_latex(float_format=lambda x: '---' if math.isnan(x) else '%.3f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complex SERPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_complex(serp):\n",
    "    for snippet in serp:\n",
    "        for c in snippet['class']:\n",
    "            if c != u'g':\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_mask(iterable, mask, inverted=False):\n",
    "    return [x for x, m in zip(iterable, mask) if (m if not inverted else not m)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N_REPETITIONS_COMPLEX = 20\n",
    "\n",
    "model_names = [\n",
    "#           'CASnod', 'CASnosat', 'CASnoreg',\n",
    "#           'CAS',\n",
    "#           'UBM', 'PBM',\n",
    "          'random', 'DCG', 'uUBM']\n",
    "\n",
    "num_complex_serps = {}\n",
    "results = []\n",
    "\n",
    "data = np.array(data)\n",
    "\n",
    "complex_serps = [is_complex(x['serp']) for x in data]\n",
    "\n",
    "for rep_index, (train_index, test_index) in enumerate(sklearn.cross_validation.StratifiedShuffleSplit(\n",
    "        complex_serps, N_REPETITIONS_COMPLEX, test_size=1/24, random_state=0)):\n",
    "    num_complex_serps[rep_index] = {}\n",
    "    train_data = data[train_index]\n",
    "    test_data = data[test_index]\n",
    "    complex_serp_mask = [is_complex(x['serp']) for x in test_data]\n",
    "    sat_labels = [int(x['sat']) for x in test_data]\n",
    "    sat_labels_complex = apply_mask(sat_labels, complex_serp_mask)\n",
    "    num_complex_serps[rep_index] = len(sat_labels_complex)\n",
    "    for m in model_names:\n",
    "        try:\n",
    "            model = MODELS[m]\n",
    "            params = model.train(train_data)\n",
    "            m_utility = [model.utility(params, x['session'], x['serp']) for x in test_data]\n",
    "            results.append({'rep': rep_index, 'model': m,\n",
    "                            'utility': apply_mask(m_utility, complex_serp_mask), 'sat': sat_labels_complex})\n",
    "        except Exception as e:\n",
    "            print >>sys.stderr, 'Exception at rep=%d, m=%s: %s' % (rep_index, m, str(e))\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "per_m_results = collections.defaultdict(lambda: {'u': [], 's': []})\n",
    "for d in [pd.read_pickle('out_heterogeneous/%d.df' % i) for i in xrange(20)]:\n",
    "    for c in d:\n",
    "        r = d[c]\n",
    "        u = r.utility\n",
    "        s = r.sat\n",
    "        assert len(u) == 1\n",
    "        assert len(s) == 1\n",
    "        per_m_results[r.name]['u'].append(u[0])\n",
    "        per_m_results[r.name]['s'].append(s[0])\n",
    "\n",
    "for m, res in per_m_results.iteritems():\n",
    "    print m, scipy.stats.pearsonr(res['u'], res['s'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sat_pearson = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sat_pearson.sort_values(['complex'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FIGS = '<DIRECTORY_TO_OUTPUT_FIGURES>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_names = ['CASnod', 'CASnosat', 'CASnoreg', 'CAS', 'UBM', 'PBM', 'random', 'DCG', 'uUBM']\n",
    "colors = sns.color_palette('Set1', n_colors=len(model_names), desat=0.3)\n",
    "\n",
    "pal = {m: colors[k] for k, m in enumerate(model_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def restyle(ax):\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('')\n",
    "    ax.xaxis.grid(color='white')\n",
    "    ax.set_xticklabels(ax.xaxis.get_majorticklabels(), rotation=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = ['CASnod', 'CASnosat', 'CASnoreg',\n",
    "          'CAS',\n",
    "          'UBM', 'PBM',\n",
    "          'random', 'uUBM',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clicks LL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = sns.boxplot(x=\"model\", y=\"value\", data=d[d['metric'] == 'click'], order=models, palette=pal)\n",
    "restyle(ax)\n",
    "ax.set_ylim([-4.5, -1.4])\n",
    "ax.figure.savefig(os.path.join(FIGS, 'll_click.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Satisfaction LL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sat_data = d[d['metric'] == 'sat'][d['model'].isin(models)]\n",
    "sat_data.set_index(['model', 'rep', 'fold'], inplace=True, verify_integrity=True)\n",
    "sat_data.sort_index(inplace=True)\n",
    "sat_data = sat_data.set_value(('CASnosat', range(N_REPETITIONS), range(N_FOLDS)), 'value', float('NaN'))\n",
    "sat_data.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = sns.boxplot(x=\"model\", y=\"value\", data=sat_data, order=models, palette=pal)\n",
    "restyle(ax)\n",
    "ax.set_ylim([-0.8, -0.2])\n",
    "ax.figure.savefig(os.path.join(FIGS, 'll_sat.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention feature analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models_attention = ['CASrank', 'CASnogeom', 'CASnoclass',\n",
    "    'CASnod', 'CAS',\n",
    "]\n",
    "colors2 = sns.color_palette('Set2', n_colors=3, desat=0.3)\n",
    "pal2 = pal.copy()\n",
    "pal2.update({m: c for m, c in zip(models_attention[:3], colors2)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ax = sns.boxplot(x=\"model\", y=\"value\", data=d_att[d_att['metric'] == 'click'], order=models_attention, palette=pal2)\n",
    "restyle(ax)\n",
    "ax.set_aspect(8)\n",
    "ax.figure.savefig(os.path.join(FIGS, 'll_click_attention.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Satisfaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = sns.boxplot(x=\"model\", y=\"value\", data=d_att[d_att['metric'] == 'sat'], order=models_attention, palette=pal2)\n",
    "restyle(ax)\n",
    "ax.set_aspect(16)\n",
    "ax.figure.savefig(os.path.join(FIGS, 'll_sat_attention.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = sns.boxplot(x=\"model\", y=\"value\", data=d_att[d_att['metric'] == 'sat pearson'], order=models_attention, palette=pal2)\n",
    "restyle(ax)\n",
    "ax.figure.savefig(os.path.join(FIGS, 'sat_pearson_attention.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on the whole dataset (to be used with TREC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def picklable_pyclick_model(pyclick_model):\n",
    "    return {'attr': pyclick_model.params[pyclick_model.param_names.attr],\n",
    "            'exam': pyclick_model.params[pyclick_model.param_names.exam]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TREC_MODELS = {\n",
    "#      'CAS': click_model.CAS(log_id_to_rel),\n",
    "#      'CAST': click_model.CAS(log_id_to_rel, use_D=False, trec_style=True),\n",
    "#      'CASTnoreg': click_model.CAS(log_id_to_rel, use_D=False, trec_style=True, reg_coeff=0),\n",
    "     'CASTnosat': click_model.CAS(log_id_to_rel, use_D=False, trec_style=True, sat_term_weight=0),\n",
    "     'CASTnosatnoreg': click_model.CAS(log_id_to_rel, use_D=False, trec_style=True, sat_term_weight=0, reg_coeff=0),\n",
    "}\n",
    "for name, model in TREC_MODELS.iteritems():\n",
    "    params = model.train(data)\n",
    "    with open('%s.params' % name, 'w') as f:\n",
    "        pickle.dump(params, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
